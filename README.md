BERT Attention Visualization Project
A complete guide to build, visualize, and deploy BERT attention mechanisms using BERTviz and Streamlit.

ðŸ“‹ Project Overview
This project visualizes how BERT (Bidirectional Encoder Representations from Transformers) pays attention to different tokens in a sentence. Think of it as an X-ray for neural networks!

What You'll Learn
How transformer attention works

Visualize attention heads in action

 Compare different model behaviors

 Deploy a web app to Streamlit Cloud

Key Technologies
BERTviz â€“ Attention visualization library

Transformers â€“ HuggingFace model hub

Streamlit â€“ Web app framework

PyTorch â€“ Deep learning backend
